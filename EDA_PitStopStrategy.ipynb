{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Download directory\n",
    "\n",
    "dir=\"/home/advaita/Downloads/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frames\n",
    "\n",
    "\n",
    "df_stops=pd.read_csv(dir+\"/pit_stops.csv\")\n",
    "df_constructor_standing=pd.read_csv(dir+\"/constructor_standings.csv\")\n",
    "df_races=pd.read_csv(dir+\"/races.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Frames\n",
    "\n",
    "commmon_columns_CS_PT=[\"raceId\"]\n",
    "commmon_columns_CS_PT_RC=[\"raceId\"]\n",
    "\n",
    "merged_CS_PT=pd.merge(df_stops,df_constructor_standing,on=commmon_columns_CS_PT,how=\"outer\")\n",
    "merged_CS_PT_RC=pd.merge(merged_CS_PT,df_races,on=commmon_columns_CS_PT_RC,how=\"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              raceId       driverId           stop            lap  \\\n",
      "count  127112.000000  116628.000000  116628.000000  116628.000000   \n",
      "mean      924.101194     532.056590       1.799705      25.332390   \n",
      "std       186.907666     388.151594       1.510880      14.841635   \n",
      "min         1.000000       1.000000       1.000000       1.000000   \n",
      "25%       873.000000      18.000000       1.000000      13.000000   \n",
      "50%       950.000000     816.000000       2.000000      25.000000   \n",
      "75%      1041.000000     832.000000       2.000000      36.000000   \n",
      "max      1144.000000     860.000000      70.000000      78.000000   \n",
      "\n",
      "       milliseconds  constructorStandingsId  constructorId         points  \\\n",
      "count  1.166280e+05           127036.000000  127036.000000  127036.000000   \n",
      "mean   8.283363e+04            25569.222339      69.295782      92.455713   \n",
      "std    3.049661e+05             4308.546747      84.177822     136.009386   \n",
      "min    1.289700e+04                1.000000       1.000000       0.000000   \n",
      "25%    2.190300e+04            25059.000000       5.000000       5.000000   \n",
      "50%    2.357200e+04            26486.000000      10.000000      34.000000   \n",
      "75%    2.637600e+04            27609.000000     131.000000     117.000000   \n",
      "max    3.069017e+06            28852.000000     215.000000     860.000000   \n",
      "\n",
      "            position           wins           year          round  \\\n",
      "count  127036.000000  127036.000000  127112.000000  127112.000000   \n",
      "mean        5.982847       0.937396    2014.125677      10.093311   \n",
      "std         3.284452       2.550235      10.236592       5.774381   \n",
      "min         1.000000       0.000000    1950.000000       1.000000   \n",
      "25%         3.000000       0.000000    2012.000000       5.000000   \n",
      "50%         6.000000       0.000000    2016.000000      10.000000   \n",
      "75%         9.000000       0.000000    2020.000000      15.000000   \n",
      "max        22.000000      21.000000    2024.000000      24.000000   \n",
      "\n",
      "           circuitId  \n",
      "count  127112.000000  \n",
      "mean       22.743289  \n",
      "std        22.936559  \n",
      "min         1.000000  \n",
      "25%         7.000000  \n",
      "50%        14.000000  \n",
      "75%        24.000000  \n",
      "max        80.000000  \n"
     ]
    }
   ],
   "source": [
    "print(merged_CS_PT_RC.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              raceId       driverId           stop            lap  \\\n",
      "count  116628.000000  116628.000000  116628.000000  116628.000000   \n",
      "mean      970.411754     532.056590       1.799705      25.332390   \n",
      "std        89.497698     388.151594       1.510880      14.841635   \n",
      "min       841.000000       1.000000       1.000000       1.000000   \n",
      "25%       887.000000      18.000000       1.000000      13.000000   \n",
      "50%       960.000000     816.000000       2.000000      25.000000   \n",
      "75%      1052.000000     832.000000       2.000000      36.000000   \n",
      "max      1132.000000     860.000000      70.000000      78.000000   \n",
      "\n",
      "       milliseconds  constructorStandingsId  constructorId         points  \\\n",
      "count  1.166280e+05           116628.000000  116628.000000  116628.000000   \n",
      "mean   8.283363e+04            26588.007408      71.625339      99.149823   \n",
      "std    3.049661e+05             1331.130241      86.192215     139.625558   \n",
      "min    1.289700e+04            24540.000000       1.000000       0.000000   \n",
      "25%    2.190300e+04            25213.000000       5.000000       6.000000   \n",
      "50%    2.357200e+04            26600.000000      10.000000      40.000000   \n",
      "75%    2.637600e+04            27703.000000     131.000000     130.000000   \n",
      "max    3.069017e+06            28852.000000     215.000000     860.000000   \n",
      "\n",
      "            position           wins           year      circuitId  \n",
      "count  116628.000000  116628.000000  116628.000000  116628.000000  \n",
      "mean        5.834354       0.967323    2016.686953      22.638500  \n",
      "std         3.100320       2.617325       4.138606      23.394307  \n",
      "min         1.000000       0.000000    2011.000000       1.000000  \n",
      "25%         3.000000       0.000000    2013.000000       7.000000  \n",
      "50%         6.000000       0.000000    2016.000000      14.000000  \n",
      "75%         8.000000       0.000000    2021.000000      24.000000  \n",
      "max        12.000000      21.000000    2024.000000      80.000000  \n"
     ]
    }
   ],
   "source": [
    "#Data cleaning\n",
    "\n",
    "\n",
    "# nan_count = merged_CS_PT_RC.isna().sum()\n",
    "# print(nan_count)\n",
    "\n",
    "# rows_with_nan = merged_CS_PT_RC[merged_CS_PT_RC.isna().any(axis=1)]\n",
    "# print(rows_with_nan)\n",
    "\n",
    "df_cleaned=merged_CS_PT_RC.drop(columns=[\"round\",\"date\",\"time_y\",\"url\",\"fp1_date\",\"fp1_time\",\"fp3_time\",\"quali_date\",\"fp2_date\",\"fp2_time\",\"fp3_date\",\"quali_time\",\"sprint_date\",\"sprint_time\"])\n",
    "# nan_count = merged_CS_PT_RC.isna().sum()\n",
    "# print(nan_count)\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Print all rows containing NaN values\n",
    "df_cleaned.dropna(inplace=True)\n",
    "df_sampled=df_cleaned.sample(n=1000,random_state=42)\n",
    "\n",
    "# print(df_cleaned.describe())\n",
    "print(df_cleaned.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuilazing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df_cleaned:\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     sns.violinplot(data=df_sampled,y=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     49\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 51\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     52\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, y_batch) \n\u001b[1;32m     54\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/katana/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 256),  \n",
    "    nn.ELU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(64, 1)  \n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input_data = df_cleaned[['circuitId', 'raceId', 'points', 'wins']].values\n",
    "target_data = df_cleaned['stop'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data_scaled, target_data, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "best_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "patience = 20  \n",
    "\n",
    "for epoch in range(1000):\n",
    "    net.train() \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = net(X_batch)  \n",
    "        loss = criterion(pred, y_batch) \n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "\n",
    "    net.eval()  \n",
    "    with torch.no_grad():\n",
    "        y_test_pred = net(X_test_tensor)  \n",
    "        val_loss = criterion(y_test_pred, y_test_tensor)  \n",
    "    \n",
    "    if val_loss.item() < best_loss:\n",
    "        best_loss = val_loss.item()\n",
    "        early_stop_counter = 0  \n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = net(X_test_tensor)\n",
    "    final_test_loss = criterion(y_test_pred, y_test_tensor)\n",
    "    print(f'\\nFinal Test Loss: {final_test_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "katana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
