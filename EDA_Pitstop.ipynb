{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, circuit_id_max, race_id_max, embedding_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for circuitId and raceId\n",
    "        self.circuit_embedding = nn.Embedding(circuit_id_max, embedding_dim)\n",
    "        self.race_embedding = nn.Embedding(race_id_max, embedding_dim)\n",
    "        \n",
    "        # Fully connected layers (considering embeddings + points + wins)\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2 + 2, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, circuit_id, race_id, points_wins):\n",
    "        # Embeddings\n",
    "        circuit_embedded = self.circuit_embedding(circuit_id)\n",
    "        race_embedded = self.race_embedding(race_id)\n",
    "        \n",
    "        # Concatenate embeddings with continuous features (points and wins)\n",
    "        x = torch.cat([circuit_embedded, race_embedded, points_wins], dim=1)\n",
    "        \n",
    "        # Forward pass through fully connected layers\n",
    "        x = torch.elu(self.fc1(x))\n",
    "        x = torch.elu(self.fc2(x))\n",
    "        x = torch.elu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "circuit_id_max = 121  # Assuming circuitId ranges from 0 to 120\n",
    "race_id_max = df_cleaned['raceId'].nunique()  # Number of unique raceId values\n",
    "embedding_dim = 8  # Dimension for embedding layers\n",
    "\n",
    "# Model instance\n",
    "net = MLPModel(circuit_id_max, race_id_max, embedding_dim).to(device)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Data preparation\n",
    "input_data = df_cleaned[['circuitId', 'raceId', 'points', 'wins']].values\n",
    "target_data = df_cleaned['stop'].values\n",
    "\n",
    "# Scale continuous features (points and wins)\n",
    "scaler = StandardScaler()\n",
    "input_data[:, 2:] = scaler.fit_transform(input_data[:, 2:])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tensor conversion\n",
    "X_train_tensor = torch.tensor(X_train[:, :2], dtype=torch.long).to(device)  # Circuit and race IDs as long (int)\n",
    "points_wins_train_tensor = torch.tensor(X_train[:, 2:], dtype=torch.float32).to(device)  # Points and wins\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test[:, :2], dtype=torch.long).to(device)\n",
    "points_wins_test_tensor = torch.tensor(X_test[:, 2:], dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Creating a DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, points_wins_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training with Early Stopping\n",
    "best_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "patience = 20\n",
    "\n",
    "for epoch in range(1000):\n",
    "    net.train()\n",
    "    for circuit_race_ids, points_wins, y_batch in train_loader:\n",
    "        circuit_ids, race_ids = circuit_race_ids[:, 0], circuit_race_ids[:, 1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = net(circuit_ids, race_ids, points_wins)  \n",
    "        loss = criterion(pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        circuit_ids_test, race_ids_test = X_test_tensor[:, 0], X_test_tensor[:, 1]\n",
    "        y_test_pred = net(circuit_ids_test, race_ids_test, points_wins_test_tensor)\n",
    "        val_loss = criterion(y_test_pred, y_test_tensor)\n",
    "    \n",
    "    if val_loss.item() < best_loss:\n",
    "        best_loss = val_loss.item()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "# Final Test Evaluation\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    final_test_loss = criterion(y_test_pred, y_test_tensor)\n",
    "    print(f'\\nFinal Test Loss: {final_test_loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "katana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
